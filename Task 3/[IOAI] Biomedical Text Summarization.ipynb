{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmJnglxe6tTa"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import json\n",
        "import numpy as np\n",
        "from icecream import ic\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def preprocessed(sentence):\n",
        "    return [ps.stem(word) for word in sentence.split() if (word.isalnum() and word not in stopwords)]\n",
        "\n",
        "\n",
        "def solve(data_raw):\n",
        "    data = json.loads(data_raw)['text']\n",
        "\n",
        "    sentences = []\n",
        "    words = []\n",
        "    for sentence in data:\n",
        "        sentence_preprocessed = preprocessed(sentence)\n",
        "        sentences.append(sentence_preprocessed)\n",
        "        words.extend(sentence_preprocessed)\n",
        "    n_sentences = len(sentences)\n",
        "    n_words = len(words)\n",
        "\n",
        "    tf_score = {}\n",
        "    for word in words:\n",
        "        if word in tf_score:\n",
        "            tf_score[word] += 1\n",
        "        else:\n",
        "            tf_score[word] = 1\n",
        "    tf_score.update((x, y / n_words) for x, y in tf_score.items())\n",
        "\n",
        "    idf_score = {}\n",
        "    for word in words:\n",
        "        if not word in idf_score:\n",
        "            idf_score[word] = [word in sentence for sentence in sentences].count(True)\n",
        "    idf_score.update((x, np.log(n_sentences / y)) for x, y in idf_score.items())\n",
        "\n",
        "    tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
        "\n",
        "    sentence_score = [ (np.sum([tf_idf_score[word] for word in sentence]) / len(sentence) if len(sentence) > 0 else 0) for sentence in sentences ]\n",
        "\n",
        "    sentence_indices_sorted = np.argsort(sentence_score)[::-1]\n",
        "\n",
        "    results = [0] * n_sentences\n",
        "\n",
        "    compression_ratio = 0.25\n",
        "    n_sentences_compressed = int(n_sentences * compression_ratio)\n",
        "\n",
        "    for i in sentence_indices_sorted[:n_sentences_compressed]:\n",
        "        results[i] = 1\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANSm5HzE6tTd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dir_test_data = './data/private/val.jsonl'\n",
        "\n",
        "results = []\n",
        "\n",
        "with open(dir_test_data, 'r') as f:\n",
        "    n_line = 0\n",
        "    while True:\n",
        "        line = f.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        n_line += 1\n",
        "\n",
        "        result = solve(line)\n",
        "        results.append(result)\n",
        "\n",
        "        if n_line == -1:\n",
        "            break\n",
        "\n",
        "results_np = np.array(results, dtype=object)\n",
        "np.save('pred.npy', results_np)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}